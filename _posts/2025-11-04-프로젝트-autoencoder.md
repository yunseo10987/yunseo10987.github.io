---
title: "[2025-11-04] AutoEncoder"
excerpt: "ì„¤ëª…ì¶© í”„ë¡œì íŠ¸"

categories:
  - Project
tags:
  - [NetWork]

permalink: /Project/[2025-11-04] AutoEncoder/

toc: true
toc_sticky: true

date: 2025-11-04
last_modified_at: 2025-11-04
---

## ğŸ¦¥ ë³¸ë¬¸

### ì •ì˜

Unlabeled dataì˜ íš¨ê³¼ì ì¸ ì½”ë”©ì„ ë°°ìš°ëŠ”ë° ì‚¬ìš©ë˜ëŠ” ì¸ê³µ ì‹ ê²½ë§ì˜ í•œ í˜•íƒœ. ì…ë ¥ ë°ì´í„°ë¥¼ ì¸ì½”ë”©í•˜ê³  ë‹¤ì‹œ ë””ì½”ë”©í•˜ë„ë¡ í›ˆë ¨ë˜ëŠ” íŠ¹ìˆ˜í•œ ì¢…ë¥˜ì˜ ì‹ ê²½ë§. 

### êµ¬ì¡°

![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-11-04%20autoencoder/image.png)

Encoder : ì…ë ¥ ë°ì´í„°ë¥¼ meaningfulí•˜ê³  compressedëœ represntationìœ¼ë¡œ ì¸ì½”ë”©. ë°ì´í„°ë¥¼ ìš”ì•½í•˜ê³  ì••ì¶•í•˜ì—¬ ì ì¬ ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê°€ì¥ í•µì‹¬ì ì¸ íŠ¹ì§•ë§Œ ë‚¨ê¸°ë„ë¡ í›ˆë ¨  

Decoder : Encoding ëœ representationì„ ë‹¤ì‹œ ì…ë ¥ ë°ì´í„°ë¡œ ë³µì› 

- ì ì¬ ê³µê°„ : ê³ ì°¨ì›ì˜ ì›ë³¸ ë°ì´í„°ê°€ ì••ì¶•ë˜ì–´ ê·¸ í•µì‹¬ íŠ¹ì§•ê³¼ íŒ¨í„´ì´ ì €ì¥ë˜ëŠ” ì €ì°¨ì›ì˜ ê³µê°„

â†’ ì…ë ¥ ë°ì´í„°ë§Œì„ í™œìš©í•˜ëŠ” ë¹„ì§€ë„ í•™ìŠµìœ¼ë¡œ ì…ë ¥ ë°ì´í„°ì™€ ë³µì›ëœ ë°ì´í„°ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ

### ëª©ì 

1. ì…ë ¥ ë°ì´í„°ë¥¼ ì˜ë¯¸ ìˆê³  ì••ì¶•ëœ í‘œí˜„ìœ¼ë¡œ ë§¤í•‘í•´ì£¼ëŠ” ì¸ì½”ë”ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ëª©ì  â†’ manifold learningì„ ìœ„í•œ ì¸ì½”ë” í•™ìŠµ. ê³¼ì í•© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•¨ 
    - ê³¼ì í•© ë¬¸ì œ : ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ë¥¼ ì§€ë‚˜ì¹˜ê²Œ í•™ìŠµí•˜ì—¬ ìƒˆë¡­ê³  ë³¸ ì ì´ ì—†ëŠ” ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ì„±ëŠ¥ì´ ê¸‰ê²©í•˜ê²Œ ë–¨ì–´ì§€ëŠ” í˜„ìƒ. í›ˆë ¨ ë°ì´í„°ì—ì„œëŠ” ì™„ë²½í•˜ì§€ë§Œ ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ì“¸ëª¨ ì—†ì–´ì§
    - Sparse Autoencoder, Denoising Autoencoder, Contractive Autoencoder ë“±ì´ ìˆìŒ
2. ì ì¬ ê³µê°„ì„ ì‹¤ì œ data distributionìœ¼ë¡œ mapping í•´ì£¼ëŠ” ë””ì½”ë”ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ëª©ì  â†’ generative modelì„ ìœ„í•œ ë””ì½”ë” í•™ìŠµ 
    - Variational Autoencoderê°€ ìˆìŒ

### ì£¼ìš” ê°œë…

- Manifold : ë‘ ì ì‚¬ì´ì˜ ê±°ë¦¬ í˜¹ì€ ìœ ì‚¬ë„ê°€ ê·¼ê±°ë¦¬ì—ì„œëŠ” ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¥¼ ë”°ë¥´ì§€ë§Œ ì›ê±°ë¦¬ì—ì„œëŠ” ê·¸ëŸ¬ì§€ ì•ŠëŠ” ê³µê°„.
    
    êµ­ì†Œì ìœ¼ë¡œëŠ” ìš°ë¦¬ê°€ ì‚¬ëŠ” í‰í‰í•œ ê³µê°„ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ì „ì²´ì ìœ¼ë¡œ íœ˜ì–´ì ¸ ìˆê±°ë‚˜ ë…íŠ¹í•œ êµ¬ì¡°ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê³µê°„. ê³ ì°¨ì› ê³µê°„ì— ë‚´ì¬í•œ ì €ì°¨ì› ê³µê°„. ë§ˆì¹˜ ì§€êµ¬.
    
    - manifold ê°€ì • : í˜„ì‹¤ì˜ ê³ ì°¨ì› ë°ì´í„°ëŠ” ì‹¤ì œë¡œëŠ” ê·¸ ê³µê°„ ì „ì²´ë¥¼ ì±„ìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í›¨ì”¬ ë‚®ì€ ì°¨ì›ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ ë”°ë¼ ë¶„í¬í•˜ê³  ìˆë‹¤ëŠ” ê°€ì •. ì´ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ ë°ì´í„° ë§¤ë‹ˆí´ë“œë¼ê³  í•¨
        
        ê³ ì°¨ì› ê³µê°„ì— ì£¼ì–´ì§„ ì‹¤ì œ ì„¸ê³„ì˜ ë°ì´í„°ëŠ” ê³ ì°¨ì› ì…ë ¥ ê³µê°„ì— ë‚´ì¬í•œ í›¨ì”¬ ì €ì°¨ì› ë§¤ë‹ˆí´ë“œì˜ ì¸ê·¼ì— ì§‘ì¤‘ë˜ì–´ ìˆë‹¤.  
        
        - íƒœì–‘ê³„ì— ê´‘í™œí•œ ëª¨ë“  ìœ„ì¹˜ëŠ” ë°ì´í„°ê°€ ì¡´ì¬í•  ìˆ˜ ìˆëŠ” ê³µê°„ì„. ê·¼ë° ì§€êµ¬ë¼ëŠ” ë§¤ë‹ˆí´ë“œ ê³µê°„ì—ë§Œ ì˜ë¯¸ ìˆëŠ” ë°ì´í„°(ìƒë¬¼)ì´ ì‚´ê³  ìˆìŒ. ê·¸ë¦¬ê³  ê·¸ í•´ë‹¹ ê³µê°„ì„ êµ­ì†Œì ìœ¼ë¡œ ë³´ë©´ 2ì°¨ì› í‰ë©´ì²˜ëŸ¼ ë³´ì„. ê·¸ë¦¬ê³  í‘œë©´ì„ ë”°ë¼ ê±¸ìœ¼ë©´ë¶€ë“œëŸ½ê²Œ ë‹¤ë¥¸ ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë¡œ ì „í™˜ì´ ê°€ëŠ¥í•¨
- Manifold Learning : ê³ ì°¨ì› ê³µê°„ì˜ ë°ì´í„°ë¥¼ ì €ì°¨ì› manifold ê³µê°„ìœ¼ë¡œ mapping ì‹œí‚¤ëŠ” í•¨ìˆ˜ë¥¼ ì°¾ëŠ” ê³¼ì •. í•™ìŠµì´ ëë‚œ autoencoderì˜ encoderë¥¼ mapping í•¨ìˆ˜ë¡œ ì‚¬ìš©
- Generative Model : ì‹¤ì œ ë°ì´í„° ë¶„í¬ë¥¼ í•™ìŠµí•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„± ëª¨ë¸. ì ì¬ ê³µê°„ì„ ì‹¤ì œ ë°ì´í„° ë¶„í¬ë¡œ ë§¤í•‘ì‹œí‚¤ëŠ” í•¨ìˆ˜ë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©ì . í•™ìŠµì´ ëë‚œ Autoencoderì˜ decoderë¥¼ ë§¤í•‘ í•¨ìˆ˜ë¡œ ì‚¬ìš©
- ì‚¬ì „ í•™ìŠµ
    - Total Error = Bias^2  + Variance + Irreducible Error
        - Bias : ì‹¤ì œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ëª¨ë¸ê³¼ ê°€ì •í•œ ëª¨ë¸ì˜ ì°¨ì´ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜. ì‹¤ì œê°’ê³¼ í‰ê·  ì˜ˆì¸¡ê°’ì˜ ì°¨ì´
        - Variance : ëª¨ë¸ë§ì— ì‚¬ìš©ë˜ëŠ” ì—¬ëŸ¬ í‘œë³¸ ë°ì´í„° ì§‘í•©ì— ëŒ€í•œ ì¶”ì •ì„ í•  ë•Œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜. ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ë¶„ì‚°. 
        ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ì‘ì€ ë³€í™”ë‚˜ ë…¸ì´ì¦ˆì— ë„ˆë¬´ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ì—¬, ìƒˆë¡œìš´ ë°ì´í„°ì…‹(ë˜ëŠ” ê²€ì¦ì…‹)ì´ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ ì˜ˆì¸¡ê°’ì˜ **ë³€ë™(ë¶„ì‚°)**ì´ ë§¤ìš° í¬ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì˜¤ë¥˜
        - Irreducible Error : ì¤„ì¼ ìˆ˜ ì—†ëŠ” ìì—°ì ì¸ ì˜¤ë¥˜
        
        Biasì™€ VarianceëŠ” trade-off ê´€ê³„. ì°¨ìˆ˜ê°€ ë†’ì•„ì§ˆ ìˆ˜ë¡(ëª¨ë¸ì´ ë³µì¡í•´ì§ˆ ìˆ˜ë¡) BiasëŠ” ì¤„ì–´ë“¤ì§€ë§Œ VarianceëŠ” ëŠ˜ì–´ë‚¨ 
        
        í›ˆë ¨ ì§‘í•©ê³¼ ê²€ì¦ ì§‘í•© ê´€ì ì—ì„œ í›ˆë ¨ ì§‘í•©ì— ëŒ€í•œ ì˜¤ë¥˜ìœ¨ì´ ë„ˆë¬´ ì‘ì•„ì§€ë©´ ê²€ì¦ ì§‘í•©ì— ëŒ€í•œ variabceê°€ ì»¤ì ¸ ê³¼ì í•© ë°œìƒ  
        
        â†’ ì í•©í•œ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì°¾ì•„ì•¼ í•¨. ë³µì¡ë„ë¥¼ ë†’ì¸ ë’¤, ë‹¤ì–‘í•œ ê·œì œ ê¸°ë²•ì„ í†µí•´ì„œ biasëŠ” ë†’ì´ê³  varianceë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „ 
        
    - ê·œì œ : ëª¨ë¸ì— ì œì•½ì„ ì£¼ì–´ì„œ ëª¨ë¸ì´ ê°€ì§„ ëª¨ë“  ìš©ëŸ‰ì„ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê²Œ í•¨ â†’ ì•”ê¸°ë¥¼ ì˜ˆë°©
- Bias-variance tradeoff in autoencoder
    
    ë°ì´í„°ë¥¼ ì˜ ë³µì›í•¨ê³¼ ë™ì‹œì—(low bias) ì²˜ìŒ ë³´ëŠ” ë°ì´í„°ë„ ì•„ìš°ë¥¼ ìˆ˜ ìˆëŠ” representationì„ í•™ìŠµ(low variance)í•˜ê¸¸ ë°”ëŒ â†’ ë³µì¡ë„ë¥¼ ë†’ì´ê³  ê·œì œ ê¸°ë²•ì„ ì ìš© 
    

### ì¢…ë¥˜ : for manifold learning

1. Sparse Autoencoder : ì€ë‹‰ì¸µ ë…¸ë“œì˜ ìˆ˜ê°€ ì…ë ¥ì¸µ ë…¸ë“œì˜ ìˆ˜ë³´ë‹¤ ë§ì€ overcomplete autoencoder êµ¬ì¡°. ì€ë‹‰ì¸µì—ì„œ í™œì„±í™”ë˜ëŠ” ë…¸ë“œê°€ ì ì–´ì§ 
    
    ![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-11-04%20autoencoder/image-1.png)
    
    - ì¼ë°˜ì ì¸ autoencoderëŠ” ì…ë ¥ê³¼ ë³µì›ëœ ì¶œë ¥ì˜ ì°¨ì´ì¸ ì¬êµ¬ì„± ì˜¤ë¥˜ë§Œ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ. í•˜ì§€ë§Œ sparse autoencoderëŠ” ì†ì‹¤í•¨ìˆ˜ì— í¬ì†Œì„± íŒ¨ë„í‹°ë¥¼ ì¶”ê°€
        - í¬ì†Œì„± íŒ¨ë„í‹° : ì ì¬ ê³µê°„ ë‰´ëŸ°ë“¤ì˜ í‰ê·  í™œì„±í™” ì •ë„ê°€ ê°€ì¥ ë‚®ì€ ê°’ì— ê°€ê¹ë„ë¡ ìœ ë„. íŒ¨ë„í‹°ë¥¼ í†µí•´ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•ì„ í¬ì°©í•˜ëŠ” ì†Œìˆ˜ì˜ ë‰´ëŸ°ì— ì˜ì¡´í•˜ë„ë¡ ê°•ì œ.
2. Denoising Autoencoder : ì…ë ¥ ë°ì´í„°ì— random noiseë‚˜ dropoutì„ ì¶”ê°€í•˜ëŠ” ê·œì œ ê¸°ë²• ì ìš©. ì…ë ¥ ë°ì´í„°ì— ì–´ë– í•œ ë…¸ì´ì¦ˆë¥¼ ë¶€ì—¬í•˜ë”ë¼ë„ manifold ìƒì—ì„œ ê°™ì€ ê³³ì— ìœ„ì¹˜í•´ì•¼ í•œë‹¤ëŠ” ê°€ì •. ì…ë ¥ë°ì´í„°ì— ì‘ì€ ë³€í™”ë¥¼ ì£¼ì–´ ì†ìƒëœ ë°ì´í„°ë¥¼ ë§Œë“¤ê³  ëª¨ë¸ì„ í†µí•´ ì†ìƒë˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ ì¶œë ¥í•˜ëŠ” ë°©ë²•. ëœ ë¯¼ê°í•œ ê°•ê±´í•œ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ  
    
    ![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-11-04%20autoencoder/image-2.png)
    
3. Contractive Autoencoder : ì‘ì€ ë³€í™”ì— ê°•ê±´í•œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ ëª©ì . DAEëŠ” ì…ë ¥ ë°ì´í„°ì˜ ì‘ì€ë³€í™”ì— ì €í•­í•˜ëŠ” ê²Œ ì¤‘ì ì´ë¼ë©´ CAEëŠ” ì¸ì½”ë”ê°€ ë””ì½”ë”ì—ì„œ ì¬êµ¬ì„±í•  ë•Œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì…ë ¥ì˜ ë³€í™”ë¥¼ ë¬´ì‹œí•˜ë„ë¡ í•˜ì—¬ íŠ¹ì§•ì„ ì¶”ì¶œí•  ë•Œ ì‘ì€ ë³€í™”ì— ëœ ë¯¼ê°í•˜ë„ë¡ ì¤‘ì   

### Application

- classification : autoencoderë¥¼ ì´ìš©í•´ í•™ìŠµì‹œí‚¨ Encoderë¥¼ Feature extractorë¡œ ì‚¬ìš©í•˜ì—¬ self-supervised learning í˜¹ì€ semi-supervised learningì— í™œìš©
- clustering : unlabeled data ê°„ì—ëŠ” ë§¤ë‹ˆí´ë“œê°€ ì¡´ì¬
- ì´ìƒì¹˜ íƒì§€ : ì •ìƒ ê´€ì¸¡ì¹˜ë§Œì„ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ì—¬ autoencoderê°€ ì´ìƒ ê´€ì¸¡ì¹˜ëŠ” ì˜ ë³µì›í•˜ì§€ ëª»í•  ê²ƒì´ë¼ëŠ” ê¸°ëŒ€ â†’ reconstruction lossê°€ í´ ê²ƒì´ë¼ ìƒê°
- ì°¨ì› ì¶•ì†Œ

```bash
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.data import random_split
import matplotlib.pyplot as plt
import numpy as np

import os
os.environ["KMP_DUPLICATE_LIT_OK"]="TRUE"

# ì˜¤í† ì¸ì½”ë” ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„±
class Autoencoder(nn.Module):
	def __init__(self):
		super(Autoencoder, self).__init__()
		
		#Encoder
		self.encoder = nn.Sequential(
			nn.Linear(28*28, 128),
			nn.ReLU(),
			nn.Linear(128, 64),
			nn.ReLU(),
			nn.Linear(64, 16),
			nn.ReLU(),
			nn.Linear(16, 2)	# ì ì¬ê³µê°„ latent space
		)
		
		#Decoder
		self.decoder = nn.Sequential(
			nn.Linear(2, 16),
			nn.ReLU(),
			nn.Linear(16, 64),
			nn.ReLU(),
			nn.Linear(64, 128),
			nn.ReLU(),
			nn.Linear(128, 28*28),
			nn.Sigmoid()
		)
	# ìˆœì „íŒŒ
	def forward(self, x):
		x_encoded = self.encoder(x) # x_encoded: ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ 784ì°¨ì›ì„ ì ì¬ ì°¨ì›ìœ¼ë¡œ ì¤„ì¸ ê°’
		x = self.decoder(x_encoded)
		return x, x_encoded

# =============================
# --- MNIST ë°ì´í„°ì…‹ í•™ìŠµ ì¤€ë¹„ ---
# =============================
# ë°ì´í„° ë³€í™˜
transform = transforms.Compose([
	transforms.ToTensor(),
])

# ì›ë³¸ í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ
full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

# í•™ìŠµ ë°ì´í„°ì…‹ì„ train, validateë¡œ ë¶„ë¦¬ (8:2)
train_size = int(0.8 * len(full_train_dataset))
val_size = len(full_train_dataset) - train_size
train_subset, val_subset = random_split(full_train_dataset, [train_size, val_size])

# í•™ìŠµë°ì´í„°, ê²€ì¦ë°ì´í„° ë¡œë“œ 
train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_subset, batch_size=1000, shuffle=False)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)

# ============================
# --- AutoEncoder í•™ìŠµ ì§„í–‰ ---
# ============================
print(f"\n===== Training Autoencoder with 2D Latent Space =====")

# ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
num_epochs = 60

train_losses = []
val_losses = []

# í•™ìŠµ ë£¨í”„
for epoch in range(num_epochs):
    model.train()
    running_train_loss = 0.0
    for data in train_loader:
        img, _ = data
        img = img.view(img.size(0), -1)
        output, _ = model(img)
        loss = criterion(output, img)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
    
    epoch_train_loss = running_train_loss / len(train_loader)
    train_losses.append(epoch_train_loss)

    # --- ê²€ì¦ ë‹¨ê³„ ---
    model.eval()
    running_val_loss = 0.0
    with torch.no_grad():
        for data in val_loader:
            img, _ = data
            img = img.view(img.size(0), -1)
            output, _ = model(img)
            loss = criterion(output, img)
            running_val_loss += loss.item()
    
    epoch_val_loss = running_val_loss / len(val_loader)
    val_losses.append(epoch_val_loss)

    # ì—í¬í¬ë§ˆë‹¤ ì†ì‹¤ê³¼ ê²€ì¦ ìˆ˜ì¹˜ ì¶œë ¥
    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')

print("Training Complete")

# ì†ì‹¤ ì‹œê°í™”
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# ==========================================================
# --- ëª¨ë¸ ë³µì›ë„ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•œ í‰ê·  ì†ì‹¤ ê³„ì‚°) ---
# ==========================================================
model.eval()
test_loss = 0.0
with torch.no_grad():
    for data in test_loader:
        imgs, _ = data
        imgs = imgs.view(imgs.size(0), -1)
        outputs, _ = model(imgs)
        loss = criterion(outputs, imgs)
        test_loss += loss.item()
test_loss /= len(test_loader)
print(f"\n--- Results for 2D Model ---")
print(f"ë³µì›ë„ (Average Test Loss): {test_loss:.4f}\n")

print(f"Visualizing reconstructed images for 2D model...")

# ================================
# --- ì‹¤ì œ ë°ì´í„°ì…‹ì„ ì´ìš©í•œ í…ŒìŠ¤íŠ¸ ---
# ================================
# í…ŒìŠ¤íŠ¸ ë°ì´í„°
dataiter = iter(test_loader)
images, _ = next(dataiter)
images_flattened = images.view(images.size(0), -1)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¨ AutoEncoderë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸
output, _ = model(images_flattened)
output = output.view(output.size(0), 1, 28, 28).detach()

# ê²°ê³¼ ì‹œê°í™”
fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))
fig.suptitle(f'Reconstruction Results (2D Latent Space)')
# ì›ë³¸ ì´ë¯¸ì§€
for i in range(10):
    img = images[i].squeeze()
    axes[0,i].imshow(img.numpy(), cmap='gray')
    axes[0,i].get_xaxis().set_visible(False)
    axes[0,i].get_yaxis().set_visible(False)
    if i == 0: axes[0,i].set_title('Originals', loc='left')

# ë³µì›ëœ ì´ë¯¸ì§€
for i in range(10):
    img = output[i].squeeze()
    axes[1,i].imshow(img.numpy(), cmap='gray')
    axes[1,i].get_xaxis().set_visible(False)
    axes[1,i].get_yaxis().set_visible(False)
    if i == 0: axes[1,i].set_title('Reconstructed', loc='left')
plt.show()

# ============================
# --- latent vactors ì‹œê°í™” ---
# ============================
model.eval()	# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½

latent_vectors = []
labels = []

with torch.no_grad():
	for data in test_loader:
		imgs, lbls = data
		imgs = imgs.view(imgs.size(0), -1)
		_, latents = model(imgs)
		latent_vectors.append(latents)
		labels.append(lbls)
		
latent_vectors = torch.cat(latent_vectors, dim=0)
labels = torch.cat(labels, dim=0)

# 2D ì‹œê°í™”
plt.figure(figsize=(12, 10))
# ê° ìˆ«ì ë ˆì´ë¸”(0-9)ì— ëŒ€í•´ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ì‚°ì ë„ ê·¸ë¦¬ê¸°
for i in range(10):
	indices = labels == i
	plt.scatter(latent_vectors[indices, 0], latent_vectors[indices, 1], label=str(i), alpha=0.7, s=15)

plt.xlabel('Latent X')
plt.ylabel('Latent Y')
plt.title('2D Latent Space Visualization')
plt.legend()
plt.grid(True)
plt.show()

# =======================================
# --- 3ì°¨ì› ì´ìƒì˜ latent vector í™•ì¸ ì‹œ ---
# =======================================
"""
from sklearn.manifold import TSNE

# t-SNE ì ìš©
tsne = TSNE(n_components=2, perplexity=30, max_iter=300)
tsne_result = tsne.fit_transform(latent_vectors)

# ì‹œê°í™”
plt.figure(figsize=(20, 8))

# t-SNE ê²°ê³¼ í”Œë¡¯
for i in range(10):
    indices = labels == i
    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=str(i), alpha=0.7, s=15)
plt.title('t-SNE Visualization of Latent Space')
plt.xlabel('t-SNE Dimension 1')
plt.ylabel('t-SNE Dimension 2')
plt.legend()
plt.grid(True)

plt.show()
"""
```

- `def __init__(self):` ìƒì„±ì
    - `super(Autoencoder, self).__init__()` : ë¶€ëª¨ ìƒì„±ì ìƒì†, ëª…ì‹œì ìœ¼ë¡œ í•´ë‹¹ ê°ì²´ì™€ í´ë˜ìŠ¤ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë„£ìŒ
    - `self.encoder, self.decoder`: ì¸ì½”ë” ë° ë””ì½”ë”
        - `nn.Sequential()` : ì—¬ëŸ¬ ê°œì˜ ì‹ ê²½ë§ ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¬¶ì–´ í•˜ë‚˜ì˜ ëª¨ë“ˆë¡œ ë§Œë“œëŠ” ë° ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤ì´ì ë©”ì†Œë“œ
        - `nn.Linear()` : ì…ë ¥ ë°ì´í„°ë¥¼ ê°€ì¤‘ì¹˜ í–‰ë ¬ê³¼ ê³±í•˜ê³  í¸í–¥ì„ ë”í•˜ëŠ” ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰. í•´ë‹¹ íŒŒë¼ë¯¸í„°ë§Œí¼ ì••ì¶• 784 â†’ 128 â†’ 64 â†’ 16 â†’ 2
        - `nn.ReLU()` : ì…ë ¥ì´ 0ë³´ë‹¤ í¬ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥, 0ë³´ë‹¤ ì‘ìœ¼ë©´ 0 ì¶œë ¥
        - `nn.Sigmoid()` : ì…ë ¥ì„ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì••ì¶•
- `def forward(self, x)` : ì¸ì½”ë”© - ë””ì½”ë”© ê³¼ì •ì„ ìˆ˜í–‰
    - `x` : í…ì„œê°’
    - `x_encoded` : ì ì¬ ì°¨ì›ìœ¼ë¡œ ì••ì¶•í•œ ê°’
- `transform` : í•¨ìˆ˜ì²˜ëŸ¼ ì‘ë™í•˜ëŠ” ê°ì²´. callable object
    - `transforms.Compose()` : ì—¬ëŸ¬ ê°œì˜ ë³€í™˜ ì‘ì—…ì„ í•˜ë‚˜ì˜ ìˆœì°¨ì ì¸ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ì–´ì¤Œ
    - `transforms.ToTensor()` : ì´ë¯¸ì§€ë¥¼ í…ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- `full_train_dataset` : í˜¸ì¶œë˜ì–´ ë§Œë“¤ì–´ì§„ ê°ì²´ëŠ” ë°ì´í„°ì…‹ì˜ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë°”ë¡œ ì˜¬ë¦¬ëŠ” ëŒ€ì‹  ì¸í„°í˜ì´ìŠ¤ë¥¼ í• ë‹¹. íŒŒë¼ë¯¸í„°ë¡œ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë¶ˆëŸ¬ì˜¬ì§€ ê²°ì •
    - `transform` ê°ì²´ë¥¼ í†µí•´ ì „ì²˜ë¦¬
- `train_loader, val_loader` : í•™ìŠµ ë°ì´í„°, ê²€ì¦ ë°ì´í„° ë¡œë“œ
    - `DataLoader()` : ë°ì´í„° ë¡œë” í´ë˜ìŠ¤, ë°ì´í„° ê°ì²´ë¥¼ ë°›ì•„ ëª¨ë¸ì´ ì²˜ë¦¬í•˜ê¸° ì‰¬ìš´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì œê³µí•´ì£¼ëŠ” ë°˜ë³µìë¥¼ ìƒì„±
- `Optimizer` : ëª¨ë¸ì´ ê³„ì‚°í•œ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´, ê° ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì–¼ë§ˆë‚˜ í¬ê²Œ ì¡°ì •í•´ì•¼í•˜ëŠ” ì§€ ê²°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
- í•™ìŠµ ë£¨í”„
    - `epoch` : ì „ì²´ ë°ì´í„° ì…‹ì„ í•™ìŠµí•˜ëŠ” íšŸìˆ˜
    - `model.train()` : í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •. í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •í•´ì•¼ ê³„ì‚° ë° ì—…ë°ì´íŠ¸ë¥¼ í™œì„±í™”
    - `for data in train_loader` : DataLoader()ë¥¼ í†µí•´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê²Œ ë¨
        - `img, _ = data` : `data`ëŠ” 32ê°œì˜ ì´ë¯¸ì§€ì™€ 32ê°œì˜ ë ˆì´ë¸”ì„ ë‹´ê³  ìˆëŠ” íŠœí”Œ í˜•íƒœ. _ë¥¼ í†µí•´ ì´ë¯¸ì§€ë§Œ imgì— í• ë‹¹ë˜ê³  ë ˆì´ë¸”ì€ ë¬´ì‹œë¨.
        - `img = img.view(img.size(0), -1)` : nn.Linear()ì— ì…ë ¥ë˜ê¸° ìœ„í•´ í‰íƒ„í™”
        - outputê³¼ imgë¥¼ ì†ì‹¤ í•¨ìˆ˜ì— ë„£ì–´ì„œ ì¬êµ¬ì„± ì˜¤ë¥˜ë¥¼ ê³„ì‚°.
        - `optimizer.zero_grad()` : ì´ì „ ì´í„°ë ˆì´ì…˜ì—ì„œ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ì˜ ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        - `loss.backward()` : ì—­ì „íŒŒë¥¼ í†µí•´ ê°€ì¤‘ì¹˜ê°€ ì˜¤ë¥˜ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ ê¸°ìš¸ê¸° ê³„ì‚°
        - `optimizer.step()` : ê³„ì‚°ëœ ê¸°ìš¸ê¸°ì™€ í•™ìŠµë¥ ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ ëª¨ë“  ê°€ì¤‘ì¹˜ ê³„ì‚°
        - `running_train_loss += loss.item()` : í•´ë‹¹ ì—í¬í¬ì˜ ì´ ì†ì‹¤ë¥ ì„ êµ¬í•˜ê¸° ìœ„í•´ ë°°ì¹˜ ë‹¨ìœ„ì—ì„œ ì†ì‹¤ë¥  í•©í•¨
    - `epoch_train_loss` : í•´ë‹¹ ì—í¬í¬ì˜ í‰ê·  ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  ê·¸ë˜í”„ ì‹œê°í™”ë¥¼ ìœ„í•´ í‰ê·  ì†ì‹¤ê°’ì„ ëª©ë¡ì— ì¶”ê°€
    - ê²€ì¦ ë‹¨ê³„ë¥¼ í†µí•´ ì—í¬í¬ë§ˆë‹¤ ê²€ì¦ì„ ì§„í–‰
