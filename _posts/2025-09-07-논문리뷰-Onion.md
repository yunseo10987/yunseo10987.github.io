---
title: "[2025-09-07] Onions Got Puzzled: On the Challenges of Mitigating Denial-of-Service Problems in Tor Onion Services"
excerpt: "Tor network"

categories:
  - Problem
tags:
  - [XSS]

permalink: /Problem/[2025-09-07] Onions Got Puzzled: On the Challenges of Mitigating Denial-of-Service Problems in Tor Onion Services/

toc: true
toc_sticky: true

date: 2025-09-07
last_modified_at: 2025-09-07
---

## 🦥 본문

초록

Tor onion services는 강력한 익명성 때문에 기존의 DoS 완화 전략 적용 불가 → 클라이언트 퍼즐 방법 사용 → 하지만 ONIONFLATION(퍼즐의 난이도를 높이는 방법) 발생. 퍼즐 인플레이션 저항성을 높이면 혼잡이 문제. 혼잡도를 막으려면 퍼즐 난이도가 문제다. 

도입

Tor network는 sender와 receiver 모두 익명 보장. 익명성과 기밀성은 좋지만 가용성은 취약. 

Tor network는 sender는 익명이라서 Dos 공격자의 출처나 그런 요청들은 차단하기 힘듦. receiver가 익명이기 때문에 서비스를 복제하는 것도 어려움 << 왜? 

→ 옛날 메커니즘인 client puzzle 방법 사용 → 일반 사용자가 충분히 모든 사용자의 퍼즐의 난이도를 높일 수 있음 → 그게 ONIONFLATION << 공격은 최소화 피해는 큼. 

Tor network의 익명성 때문에 빠르게 정확하게 개별된 피드백을 주는 데 어려움이 있어서 클라이언트 퍼즐의 대규모 운영은 어려움 → 즉, 상충되는 문제 발생(난이도 문제 vs 혼잡 문제) → 새로운 업데이트 알고리즘 제안(인플레이션 공격은 막으면서(공격 비용증가 ) 일시적인 혼잡 방어(공격 강도에 비례한 난이도 상승))

토르 네트워크

익명 네트워크. relay라는 일련의 서버들을 통해 라우팅되는 데, 데이터의 원래 출처는 숨겨짐

onion system은 이 토르 네트워크를 이용하여 sender와 receiver를 숨김. 특별한 주소 방법인 .onion 방식으로 익명성 유지. 유니크한 .onion 주소는 식별자 역할. 사용자가 오니온 서비스를 연결하고 싶을 때, 이 주소를 사용하여 연결 설립. 모든 과정은 토르 relay를 통해 라우팅댓글 추가

++추가로 토르 네트워크를 살펴보면 입구 노드, 중계 노드, 출구 노드가 있음. 사용자가 접속하면 무작위로 서킷을 설정함. 암호키가 여러 개 차례 대로 여러 겹의 암호화되고 노드마다 복호화 진행.

.onion은 숨겨진 서비스로 Tor 네트워크를 통해서만 접근 가능

Introduction-Flooding attacks

RP(rendezvous point). 클라이언트와 서비스는 RP까지 서킷 설정. 

옛날에는 onions 서비스의 리스트에서 클라이언트가 선택. 근데 이건 다양한 공격에 노출된다. 그래서 IP(introduction point)가 RP의 분포된 RP의 선택을 보장

1. 클라이언트가 RP 선택하고 서킷 설정
2. IP을 통해 onion 서비스에 introduction request를 보냄
    1. intro-request는 선택된 RP의 서킷을 설정한다고 요청하는 것
3. relay의 집합인 IP들은 intro-request를 클라이언트에서 onion 서비스로 포워딩. 익명성 보존

++

동작 방식

1. 숨겨진 서비스는 자신이 접속을 받을 수 있는 지점으로 토르 릴레이를 연결 → IP
2. 클라이언트가 해당 숨겨진 서비스의 IP를 목록을 조회
3. 클라이언트는 RP를 하나 선택한 후 서킷 설정 
4. 그 후 IP를 통해 서비스에게 해당 RP에서  만나자고 요청(intro-request)
5. IP를  통해 받은 서비스는 RP까지 서킷을 설정하고 해당 RP에서 메시지를 주고 받음 

하지만 위 방식은 많은 intro-request를 처리하는 intro-flooding이라는 공격에 노출 → 타겟된 서비스는 너무 많은 RP에 해당하는 많은 서킷을 설정하게 된다.  

해당 논문에서는 intro-flooding이라는 공격의 대응 방법에 국한 

→ client puzzle 방법을 사용

다른 DoS 완화 정책들이 있지만 익명성 우선 정책 때문에 적용 불가한 이유 

1. Source-based filtering 방법
    
    rate-limiting, 의심되는 소스 밴, 트래픽 우선순위, 스크러빙 서비스(트래픽을 분석하고 정상적인 요청과 비정상적인 요청 구분)로 리디렉션. 같은 방식. 
    

→ 하지만 익명성 때문에, 다른 두 소스를 구분할 수 없음. 위에 있는 속도 제한 메커니즘은 IP에 구현되어 있는 트래픽 출처를 구분하지 않은 intro-request 속도 제한과는 다른 속도 제한임. 

1. Replication-based 완화 정책
    
    복제를 통해 서비스 과잉 공급 방법은 onion 서비스의 익명성과 탈중앙화 때문에 힘듦. 추가적인 onion 서비스 인스턴스 뿐만 아니라 사용자 익명성을 유지하는 방식으로 인스턴스를 분산해야 함. 
    
    수평적 확장 방식이 제안되지만 다음과 같은 제한이 있음
    
    1. DoS 공격을 받으면 클라이언트는 IP 에 접근하는 게 불가
    2. 복제의 최대량이 제약이 됨. 
2. 소스 테스팅을 통한 완화 정책
    
    클라이언트를 테스트 하는 방식. CPATCHA 같은 방식은 사람과 봇을 구별. 하지만 onion service에서 sender 익명성 때문에 비효율적. RP 서킷을 설립한 후에 CAPTCHA를 해야 하기 때문에, intro-request를 받은 이후에만 가능 → intro-flooding 못 막음
    

Client Puzzle 

proof-of-work라는 아이디어는 공격자와 방어자의 불균형을 처리하는 데 효과적. 공격자는 공격을 발생하기 위해서 많은 자원을 써야 하지만 방어자는 최소한의 노력만 하면됨. 

DoS에서, 서버는 클라이언트 접근을 허락하기 전에 암호 퍼즐을 클라이언트가 풀게 함. 정상 사용자는 작은 부담을 주지만 많은 퍼즐을 풀어야 하는 공격자에게는 큰 부담을 줌 → TCP/IP, TLS, internet 키 교환에 연구됨. 하지만 널리 적용되지 못한 까닭은, 정상 사용자에게 타당하지 않고 사소하지 않은  부담을 준다는 것 때문. 몇 초라는 게 오늘날엔 사실 별로 좋은 경험은 아님. 

하지만 onion 서비스에서는 다른 실용적인 대안이 없어서 사용. onion 서비스에서 연결 설립 자체가 오래 걸리기 때문에 client puzzle에 의한 부담은 미미함 

하지만 ONIONFLATION이라는 공격에 취약 

basic puzzle design 

서비스를 받기 전에 암호 퍼즐을  풀어야 하는 proof-of-work 디자인. 각 퍼즐은 특정 파라미터와 선행 계산 공격을 막는 시드를 포함. 시드가 변경되면 이전의 유효한 정답들은 무효화. 퍼즐을 받자마자 클라이언트는 유효한 답을 찾기 위해 반복적으로 암호 작업을 수행, 반면에 서버는 아주 효율적으로, 적은 노력으로 제시된 해답을 증명. 

특징 1. ASIC 저항

Application-Specific Integrated circuits. 퍼즐을 푸는 게 최적화된 맞춤 반도체. 일반 사용자와는 불공정한 이점을 갖고 있음. ASIC에 대항하기 위해 새로운 시드를 위한 내부 로직을 랜덤화하는 해시 함수가 있음 

왜? : ASIC는 특정 연산만을 빠르게 연산하는 고정된 로직을 가지는 데, 내부 로직을 바꿔서 ASIC를 완화함.

특징 2. 메모리 요구사항

상당한 RAM 작업을 요구.  퍼즐을 목적으로한 특수 하드웨어는 RAM이 제한적. 그렇기 때문에 사용자와 특수 하드웨어 사용자와의 성능 격차를 줄임

특징 3. 선형적 난이도 증가

전통적인 것은 지수적 증가. 선형적으로 증가하여 난이도를 세밀하게 조정할 수 있음 → 불필요한 난이도 증가는 일반 사용자의 불편 초래, 적당한 난이도 조정으로 일반 사용자는 냅두고 공격에는 대응

End-to-End Client Puzzle Operation 

![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-09-07%20Onion/image.png)

클라이언트는 디렉토리 서버 중 하나에서 디스크립터를 가져와서 시드, 난이도, 서비스 고유의 식별 문자를 추출한다.  이러한 파라미터를 통해 퍼즐을 풀고 IP를 통해 intor-request를 보냄. intro-request를 받자마자 서비스는 퍼즐 해답을 증명하고 요청을 우선순위 큐(퍼즐 난이도에 따른 요청을 분류한 우선순위큐)에 인큐함. 서비스는 디큐하고 RP에 대한 서킷을 설립. 서비스가 요청을 디큐하는 속도는 초당 250개로 제한.  

단순히 이 서비스 속도를 늘리는 것(서비스 처리 속도를 늘려 요청을 빠르게 처리하는 것은 일반적인 DoS 완화 정책임.)은 Tor에서는 불가. 요청을 빠르게 처리하는 건(즉, RP 서킷을 많이 설정하는 것) Tor 네트워크에 부담.

난이도는 클라이언트가 선택할 수 있음. 디폴트는 서비스가 제안한 난이도. 가장 중요한 작업은 서비스가 퍼즐 난이도 조절 업데이트 방법. 지금은 업데이트 라운드가 끝날 때마다 주기적으로 업데이트. 

위 그림에서 처럼 라운드 n을 바탕으로 난이도 n+1을 적용. 그리고 디렉토리 서버의 디스크립터에 초함

DUA

난이도 업데이트 알고리즘. 우선 순위큐의 상태에 기반한 난이도 업데이트. 즉, 혼잡 상태를 감지하여 난이도 조절 . 조정의 양은 AIMD 방식. 즉 혼잡이 발견되면 난이도 하나를 올리고 감지되지 않으면 2/3로 감소 

제안된 난이도를 높여서 혼잡도에 빠르게 대응하는 다른 규칙을 적용. 예를 들어, 높은 난이도의 요청이 trimming(난이도의 요청을 처리하지 못하고 버리는 상황)이 되면 혼잡이라고 판단하고 큐 상태를 보고 난이도를 높임. 

Client puzzle 효율성을 판단하기 위해 실험을 해봄.

실험

토르 네트워크에서 24시간 동안 많은 intro-request를 보냄. 요청은 제약 내 최대 속도로 전송. CPU는 30개 코어로 ONIONFLATION 구현. 초당 최대 505개의 요청. 평균적으로 초당 47개의 요청. onion 퍼즐이 없는 경우 마비.

![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-09-07%20Onion/image-1.png)

X 축은 시간, Y축은 업데이트 라운드에 대한 요청의 수, 두번째 Y축은 난이도. DUA가 요청의 수를 제어 가능한 레벨로 유지하게 한다. 상대방은 난이도가 증가하면 제안된 퍼즐을 푸는데 실패하는 게 늘어남 

8시와 12시에 비슷한 요청이 전송됐지만 8시가 더 낮은 난이도를 보여줌 → trimming 메커니즘(너무 많은 요청이 들어왔을 때 큐의 일부 요청을 제거 ) 때문, 패킷 버스트 패턴(특정 시간에 대량으로 전송되는 패턴)에 따라 반응 

DUA 알고리즘 

```jsx
state:
Dsug[n]: The suggested puzzle difficulty at round n.
Dmax−trim[n]: The highest puzzle difficulty of trimmed requests
during round n. Trimming can occur when requests that are too
old (i.e., enqueued more than 15 seconds earlier) are dequeued,
or when the queue reaches its capacity (i.e., 16,384 or 17,500 requests, depending on the configuration). For the latter, the service
discards half of the queue.
∑Denqueued[n]: The sum of all puzzle difficulties of enqueued
requests during round n.
rendhandled[n]: The number of handled requests during round n.
f lagcongestion: A flag which is set if the priority queue is filled with
a certain number of requests (i.e., 16 or 63 requests, depending
on the configuration). It is unset at the start of each round.
decision:
at the end of each update round, the service
1: if Dmax−trim[n] > Dsug[n] then
2: increases the suggested difficulty
3: else if f lagcongestion then
4: if at least one request remains whose puzzle difficulty is
Dsug[n] or high then
5: increases the suggested difficulty
6: end if
7: else if the current number of requests in the queue is below a
threshold (i.e., 16 or 63 requests, depending on the configuration) then
8: decreases the suggested difficulty
9: else
10: maintains the suggested difficulty
11: end if
increase:
Dsug[n+1] ← max(
∑Denqueued [n]
rendhandled [n]
,Dsug[n] +1)
decrease:
Dsug[n+1] ← 2
3 ×Dsug[n]
```

난이도 증가 : 평균 난이도 와 (제안된 난이도 + 1) 중 큰 값으로 변경

Dmax-trim[n] > Dsug[n] : 버려진 요청의 난이도가 현재 제안된 난이도보다 높다는 것은 높은 난이도로 뚫고 온 공격 트래픽을 버렸다는 뜻. → 공격이 감지되어 난이도를 올림. (공격자는 공격을 위해 제안된 난이도보다 높은 난이도를 설정하고 풀고 들어옴 → 왜냐면 설정된 난이도를 높여도 계속 공격하려고 )

flagcongestion : 혼잡 상태이고 더 높은 난이도 요청이 큐에 남아 있으면 난이도가 낮다는 뜻임(왜냐면 현재 난이도 또는 그 이상의 난이도를 풀고 온 요청이 많다는 것이기 때문). 난이도를 올림

난이도 감소 : 2/3 

요청의 수가 특정 기준치보다 낮아지면 난이도를 낮춤

난이도 유지

둘 다 아니면 유지 

![image.png](https://yunseo10987.github.io/assets/images/posts_img/2025-09-07%20Onion/image-2.png)

X축은 사용자 대기시간, Y축은 서비스를 이용한 클라이언트 비율. 퍼즐 시스템이 공격으로 인한 대기시간을 줄여준다는 점에서 intro-flooding 공격을 완화시킴을 보임